{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## The Framework\n",
        "There is a good library in Python and this is numpy. [Numpy](https://numpy.org/) is bottom of the Python data science. Numpy is easy to use and many good libraries runs with numpy. Although Numpy is actually very fast on single cpu, many library tring to replace numpy because numpy can't operate on GPU or on parallel. There is numba but not it is not entirely covers all the details like scipy and scikit-learn<br/>\n",
        "<b> Note: Performance is nothing without correct and unreadable code </b><br/>\n",
        "<br/>\n",
        "I've seen two good libraries that can replace the numpy: [Pytorch]((https://pytorch.org/)) and [Cupy](https://cupy.chainer.org/).<br/>\n",
        "Cupy: is part of the chainer framework made by japanies startup company. Cupy can uses without chainer framework but isn't a full deep learning framework and it isn't in our scope right now.\n",
        "<br/>\n",
        "\n",
        "<br/>\n",
        "I want to intruduce ported from lua torch and redesigned Pytorch. Pytorch has a very good interface to numpy and many operations similar to numpy users. It is a bit low level but it is good to research. In data science or deep learning people spend more time on research rather than production <br/>\n",
        "\n",
        "Research framework doesn't mean to you can't use in production. Pytorch has a jit complier and compiles scripts to [torchscript](https://pytorch.org/docs/stable/jit.html) and than use in c++. In this way Pytorch bridges research and production.<br/>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Philosophy of PyTorch\n",
        "1. Stay out of the way<br/>\n",
        "2. Cater to the impatient<br/>\n",
        "3. Promote linear code-flow<br/>\n",
        "4. Full interop with the Python ecosystem<br/>\n",
        "5. Be as fast as anything else<br/>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor \n",
        "Tensor is the most essential part of the deep learning.<br/><br/>\n",
        "\n",
        "In math numbers represented as <b>Scalar, Vector or Matrix</b> but In data science numbers represented as tensors. Basicly tensor is a <b>n dimensational array</b>(or the orher word <b>n rank array</b>).<br/>\n",
        "<br/>\n",
        "- A scalar is a 0 dimensional tensor\n",
        "- A vector is a 1 dimensional tensor\n",
        "- A matrix is a 2 dimensional tensor\n",
        "- A nd-array is an n dimensional tensor\n",
        "<br/><br/>\n",
        "#### Stop using words like vector, array or matrix. <b>Everything is tensor in data science. I will use tensor all the time.</b>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "# other 3rd party imports\n",
        "import numpy as np\n",
        "\n",
        "print(\"Cuda version: \", torch.version.cuda)\n",
        "print(\"Cudnn enabled?: \", torch.backends.cudnn.enabled)\n",
        "print(\"Cudnn version: \", torch.backends.cudnn.version())\n",
        "print(\"torch version: \", torch.__version__)\n",
        "print(\"torchvision version: \", torchvision.__version__)\n",
        "print(\"numpy version: \", np.__version__)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cuda version:  10.1\n",
            "Cudnn enabled?:  True\n",
            "Cudnn version:  7603\n",
            "torch version:  1.4.0.dev20191202\n",
            "torchvision version:  0.5.0.dev20191203\n",
            "numpy version:  1.17.4\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Tensor backend uses: \", device)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor backend uses:  cuda\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch tensors can operate numpy like operations <br/>\n",
        "note: I am using lastest versyion Pytorch, torchvision, cuda and cudnn right now. If you want to make a product than use stable version."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, Pytorch uses Cuda but this doeesn't mean you cannot run if you don't have Nvidia Gpu. Actually if you don't have a big data and big model don't use Gpu. Coping data to gpu and get back it is very time consuming process. If you do wihout big data and big model you will lose time instead of increasing speed(I tested the speed in my computer).<br/>\n",
        "There is also a weak support for amd gpus(rocm) but you have to use linux or mac and recompile everthing from scratch.\n",
        "#### Okey! Let's cook<br/>\n",
        "<img src=\"https://deeplizard.com/images/pizza-744405_1920.jpg\" alt=\"pizza in stone oven\">"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([1,2,3])\n",
        "print(t)\n",
        "# to the device or GPU\n",
        "print(t.cuda())\n",
        "print(t.to(device))\n",
        "# to the cpu\n",
        "print(t.cpu())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3])\n",
            "tensor([1, 2, 3], device='cuda:0')\n",
            "tensor([1, 2, 3], device='cuda:0')\n",
            "tensor([1, 2, 3])\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = [\n",
        "    [1,2,3,123],\n",
        "    [4,5,6,456],\n",
        "    [7,8,9,789],\n",
        "]\n",
        "t = torch.tensor(t)\n",
        "\n",
        "print(t[0])\n",
        "print(t[1])\n",
        "print(t[2])\n",
        "\n",
        "print(t[0][0])\n",
        "print(t[1][0])\n",
        "print(t[2][0])\n",
        "\n",
        "print(t[0][1])\n",
        "print(t[1][1])\n",
        "print(t[2][1])\n",
        "\n",
        "print(t[0][2])\n",
        "print(t[1][2])\n",
        "print(t[2][2])\n",
        "\n",
        "print(t[0][3])\n",
        "print(t[1][3])\n",
        "print(t[2][3])\n",
        "\n",
        "print(type(t))\n",
        "print(t.size())\n",
        "print(t.shape)\n",
        "print(\"dimensions: \", len(t.shape))\n",
        "print(torch.tensor(t.shape).prod())\n",
        "print(t.numel())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([  1,   2,   3, 123])\n",
            "tensor([  4,   5,   6, 456])\n",
            "tensor([  7,   8,   9, 789])\n",
            "tensor(1)\n",
            "tensor(4)\n",
            "tensor(7)\n",
            "tensor(2)\n",
            "tensor(5)\n",
            "tensor(8)\n",
            "tensor(3)\n",
            "tensor(6)\n",
            "tensor(9)\n",
            "tensor(123)\n",
            "tensor(456)\n",
            "tensor(789)\n",
            "<class 'torch.Tensor'>\n",
            "torch.Size([3, 4])\n",
            "torch.Size([3, 4])\n",
            "dimensions:  2\n",
            "tensor(12)\n",
            "12\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"reshaped t:\", t.reshape(1,t.numel()))\n",
        "print(\"shape of reshaped t:\", t.reshape(1,t.numel()).shape)\n",
        "print(\"t shape isn't changed(mutated) itself: \\n\", t)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reshaped t: tensor([[  1,   2,   3, 123,   4,   5,   6, 456,   7,   8,   9, 789]])\n",
            "shape of reshaped t: torch.Size([1, 12])\n",
            "t shape isn't changed(mutated) itself: \n",
            " tensor([[  1,   2,   3, 123],\n",
            "        [  4,   5,   6, 456],\n",
            "        [  7,   8,   9, 789]])\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytorch Image Dimensaions\n",
        "[Batch size, Color channels, Height, Width]<br/>\n",
        "If you want to use numpy interface you should change dimensaion order."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Tensor attributes](https://deeplizard.com/learn/video/jexkKugTg04)\n",
        "In the end of the day, Pytorch is a tensor implementation. All tensors have a type and type should match each other.<br/>\n",
        "<table class=\"table table-sm table-hover\">\n",
        "                                                    <tbody>\n",
        "                                                        <tr>\n",
        "                                                            <th>Data type</th>\n",
        "                                                            <th>dtype</th>\n",
        "                                                            <th>CPU tensor</th>\n",
        "                                                            <th>GPU tensor</th>\n",
        "                                                        </tr>\n",
        "                                                        <tr>\n",
        "                                                            <td>32-bit floating point</td>\n",
        "                                                            <td>torch.float32</td>\n",
        "                                                            <td>torch.FloatTensor</td>\n",
        "                                                            <td>torch.cuda.FloatTensor</td>\n",
        "                                                        </tr>\n",
        "                                                        <tr>\n",
        "                                                            <td>64-bit floating point</td>\n",
        "                                                            <td>torch.float64</td>\n",
        "                                                            <td>torch.DoubleTensor</td>\n",
        "                                                            <td>torch.cuda.DoubleTensor</td>\n",
        "                                                        </tr>\n",
        "                                                        <tr>\n",
        "                                                            <td>16-bit floating point</td>\n",
        "                                                            <td>torch.float16</td>\n",
        "                                                            <td>torch.HalfTensor</td>\n",
        "                                                            <td>torch.cuda.HalfTensor</td>\n",
        "                                                        </tr>\n",
        "                                                        <tr>\n",
        "                                                            <td>8-bit integer (unsigned)</td>\n",
        "                                                            <td>torch.uint8</td>\n",
        "                                                            <td>torch.ByteTensor</td>\n",
        "                                                            <td>torch.cuda.ByteTensor</td>\n",
        "                                                        </tr>\n",
        "                                                        <tr>\n",
        "                                                            <td>8-bit integer (signed)</td>\n",
        "                                                            <td>torch.int8</td>\n",
        "                                                            <td>torch.CharTensor</td>\n",
        "                                                            <td>torch.cuda.CharTensor</td>\n",
        "                                                        </tr>\n",
        "                                                        <tr>\n",
        "                                                            <td>16-bit integer (signed)</td>\n",
        "                                                            <td>torch.int16</td>\n",
        "                                                            <td>torch.ShortTensor</td>\n",
        "                                                            <td>torch.cuda.ShortTensor</td>\n",
        "                                                        </tr>\n",
        "                                                        <tr>\n",
        "                                                            <td>32-bit integer (signed)</td>\n",
        "                                                            <td>torch.int32</td>\n",
        "                                                            <td>torch.IntTensor</td>\n",
        "                                                            <td>torch.cuda.IntTensor</td>\n",
        "                                                        </tr>\n",
        "                                                        <tr>\n",
        "                                                            <td>64-bit integer (signed)</td>\n",
        "                                                            <td>torch.int64</td>\n",
        "                                                            <td>torch.LongTensor</td>\n",
        "                                                            <td>torch.cuda.LongTensor</td>\n",
        "                                                        </tr>\n",
        "                                                    </tbody>\n",
        "                                                </table>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.Tensor()\n",
        "print(type(t))\n",
        "print(t.dtype)\n",
        "print(t.device)\n",
        "print(t.layout)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.float32\n",
            "cpu\n",
            "torch.strided\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Types must match"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.tensor([1,2,3])\n",
        "t2 = torch.tensor([1.,2.,3.])\n",
        "print(t1.dtype)\n",
        "print(t2.dtype)\n",
        "print(t1 * t2)\n",
        "print((t1 * t2).dtype)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n",
            "torch.float32\n",
            "tensor([1., 4., 9.])\n",
            "torch.float32\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating tensors using data\n",
        "These are the primary ways of creating tensor objects (instances of the torch.Tensor class), with data (array-like) in PyTorch:\n",
        "\n",
        "1. torch.Tensor(data)\n",
        "2. torch.tensor(data)\n",
        "3. torch.as_tensor(data)\n",
        "4. torch.from_numpy(data)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>class constructor</b>: creates object but not with all parameters. exp:  torch.Tensor<br/>\n",
        "<b>factory functions</b>: builds tensor objects for us. it allows more dynamic object creation. exp: torch.tensor, torch.as_tensor, torch.from_numpy"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"torch default dtype: \", torch.get_default_dtype())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch default dtype:  torch.float32\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array([1,2,3])\n",
        "print(\"np.array([1,2,3]).dtype: \", np.array([1,2,3]).dtype)\n",
        "\n",
        "# class constructor\n",
        "o1 = torch.Tensor(data) # no dtype ;)\n",
        "# all 3 of that factory functions\n",
        "o2 = torch.tensor(data)\n",
        "o3 = torch.as_tensor(data)\n",
        "o4 = torch.from_numpy(data)\n",
        "\n",
        "print(\"Tensor: \", o1)\n",
        "print(\"tensor: \", o2) # reflects input type\n",
        "print(\"as_tensor: \", o3)\n",
        "print(\"from_numpy: \", o4)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "np.array([1,2,3]).dtype:  int32\n",
            "Tensor:  tensor([1., 2., 3.])\n",
            "tensor:  tensor([1, 2, 3], dtype=torch.int32)\n",
            "as_tensor:  tensor([1, 2, 3], dtype=torch.int32)\n",
            "from_numpy:  tensor([1, 2, 3], dtype=torch.int32)\n"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor creation has a little changes with different funcitons.<br/>\n",
        "torch.tensor reflects input type.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# they are both the same\n",
        "print(torch.tensor(np.array([1.,2.,3.])))\n",
        "print(torch.tensor(np.array([1.,2.,3.]), dtype=torch.float64))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3.], dtype=torch.float64)\n",
            "tensor([1., 2., 3.], dtype=torch.float64)\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Value modification changes value differently<br/>\n",
        "<table class=\"table table-sm table-hover\">\n",
        "                                                    <tbody>\n",
        "                                                        <tr>\n",
        "                                                            <th>\n",
        "                                                                Share Data(much more fast)\n",
        "                                                            </th>\n",
        "                                                            <th>\n",
        "                                                                Copy Data\n",
        "                                                            </th>\n",
        "                                                        </tr>\n",
        "                                                        <tr>\n",
        "                                                            <td>\n",
        "                                                                torch.as_tensor() -> <b> best option </b>\n",
        "                                                            </td>\n",
        "                                                            <td>\n",
        "                                                                torch.tensor() -> <b> best option </b>\n",
        "                                                            </td>\n",
        "                                                        </tr>\n",
        "                                                        <tr>\n",
        "                                                            <td>\n",
        "                                                                torch.from_numpy() {shares only with numpy}\n",
        "                                                            </td>\n",
        "                                                            <td>\n",
        "                                                                torch.Tensor() {doesn't contaion any type}\n",
        "                                                            </td>\n",
        "                                                        </tr>\n",
        "                                                    </tbody>\n",
        "                                                </table>\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array([1,2,3])\n",
        "\n",
        "o1 = torch.Tensor(data)\n",
        "o2 = torch.tensor(data)\n",
        "o3 = torch.as_tensor(data)\n",
        "o4 = torch.from_numpy(data)\n",
        "\n",
        "data[0] = 0\n",
        "data[1] = 0\n",
        "data[2] = 120\n",
        "\n",
        "# there is something happened. Exemine what is going on.\n",
        "print(\"Tensor: \", o1) # no dtype ;)\n",
        "print(\"tensor: \", o2) # reflects input type\n",
        "print(\"as_tensor: \", o3)\n",
        "print(\"from_numpy: \", o4)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor:  tensor([1., 2., 3.])\n",
            "tensor:  tensor([1, 2, 3], dtype=torch.int32)\n",
            "as_tensor:  tensor([  0,   0, 120], dtype=torch.int32)\n",
            "from_numpy:  tensor([  0,   0, 120], dtype=torch.int32)\n"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# take is back to numpy\n",
        "print(o3.numpy())\n",
        "print(type(o3.numpy()))\n",
        "print(o4.numpy())\n",
        "print(type(o4.numpy()))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0   0 120]\n",
            "<class 'numpy.ndarray'>\n",
            "[  0   0 120]\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Some of creation options"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"torch.eye(2): \", torch.eye(2))\n",
        "print(\"torch.zeros(2,2): \", torch.zeros(2,2))\n",
        "print(\"torch.ones(2,2): \", torch.ones(2,2))\n",
        "print(\"torch.rand(2,2): \", torch.rand(2,2))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.eye(2):  tensor([[1., 0.],\n",
            "        [0., 1.]])\n",
            "torch.zeros(2,2):  tensor([[0., 0.],\n",
            "        [0., 0.]])\n",
            "torch.ones(2,2):  tensor([[1., 1.],\n",
            "        [1., 1.]])\n",
            "torch.rand(2,2):  tensor([[0.8031, 0.6033],\n",
            "        [0.0572, 0.8267]])\n"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor operations\n",
        "### Flatten, Reshape, and Squeeze\n",
        "Most of the time i have spent time on dimensions. There operations "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([\n",
        "    [1,1,1,1],\n",
        "    [2,2,2,2],\n",
        "    [3,3,3,3]\n",
        "])\n",
        "print(t.size())\n",
        "print(t.shape)\n",
        "print(\"dimensions: \", len(t.shape))\n",
        "print(torch.tensor(t.shape).prod())\n",
        "print(t.numel())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 4])\n",
            "torch.Size([3, 4])\n",
            "dimensions:  2\n",
            "tensor(12)\n",
            "12\n"
          ]
        }
      ],
      "execution_count": 14,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reshape\n",
        "There is a little bit difference with reshaping function<br/>\n",
        "<b>contigious data</b>: Pytorch avoids the data coping to make operations faster even when concatenating or stuking tensors. Contigious mean data continuous in one piace on ram. If you want to create and copy all data into a new contigious array use contigious function.\n",
        "- view: Operates on \"contigious\" data. if it is not. throws and error.\n",
        "- reshape: if data contigious uses view otherwise makes contigious and then uses view\n",
        "- resize: There isn't guanties to protect the number of data. It samples and creates a new tensor"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# change the shape without changing the rank\n",
        "print(\"t.reshape(1,12): \", t.reshape(1,12))\n",
        "print(\"t.reshape(2,6): \", t.reshape(2,6))\n",
        "print(\"t.reshape(3,4): \", t.reshape(3,4))\n",
        "print(\"t.reshape(4,3): \", t.reshape(4,3))\n",
        "print(\"t.reshape(6,2): \", t.reshape(6,2))\n",
        "print(\"t.reshape(12,1): \", t.reshape(12,1))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t.reshape(1,12):  tensor([[1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3]])\n",
            "t.reshape(2,6):  tensor([[1, 1, 1, 1, 2, 2],\n",
            "        [2, 2, 3, 3, 3, 3]])\n",
            "t.reshape(3,4):  tensor([[1, 1, 1, 1],\n",
            "        [2, 2, 2, 2],\n",
            "        [3, 3, 3, 3]])\n",
            "t.reshape(4,3):  tensor([[1, 1, 1],\n",
            "        [1, 2, 2],\n",
            "        [2, 2, 3],\n",
            "        [3, 3, 3]])\n",
            "t.reshape(6,2):  tensor([[1, 1],\n",
            "        [1, 1],\n",
            "        [2, 2],\n",
            "        [2, 2],\n",
            "        [3, 3],\n",
            "        [3, 3]])\n",
            "t.reshape(12,1):  tensor([[1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [2],\n",
            "        [2],\n",
            "        [2],\n",
            "        [2],\n",
            "        [3],\n",
            "        [3],\n",
            "        [3],\n",
            "        [3]])\n"
          ]
        }
      ],
      "execution_count": 15,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Changing shape by squeezing and unsqueezing\n",
        "squeeze(Expends): removes one dimension from tensor.<br/>\n",
        "unsqueeze(Shirnks): adds one dimension from tensor."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(t.reshape(1,12))\n",
        "print(t.reshape(1,12).shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3]])\n",
            "torch.Size([1, 12])\n"
          ]
        }
      ],
      "execution_count": 16,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(t.reshape(1,12).squeeze())\n",
        "print(t.reshape(1,12).squeeze().shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3])\n",
            "torch.Size([12])\n"
          ]
        }
      ],
      "execution_count": 17,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(t.reshape(1,12).squeeze().unsqueeze(dim=0))\n",
        "print(t.reshape(1,12).squeeze().unsqueeze(dim=0).shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3]])\n",
            "torch.Size([1, 12])\n"
          ]
        }
      ],
      "execution_count": 18,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Flatten\n",
        "removes all of the axis except for '1'. creates 1 dim.<br/>\n",
        "To flatten a tensor, we need to have at least two axes. This makes it so that we are starting with something that is not already flat. Let’s look now at a hand written image of an eight from the MNIST dataset. This image has 2 distinct dimensions, height and width.\n",
        "<img src=\"https://deeplizard.com/images/CNN%20Flatten%20Operation%20Visualized.png\" alt=\"image and flattened output\">"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten(t):\n",
        "    t = t.reshape(1, -1) #calculates other dims\n",
        "    t = t.squeeze()\n",
        "    return t"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flatten(t) # gives me squeezed version ;)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.reshape(1,-1)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 21,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concatenating tensors\n",
        "We combine tensors using the cat() function, and the resulting tensor will have a shape that depends on the shape of the two input tensors."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.tensor([\n",
        "    [1,2],\n",
        "    [3,4]\n",
        "])\n",
        "t2 = torch.tensor([\n",
        "    [5,6],\n",
        "    [7,8]\n",
        "])\n",
        "print(t1.shape)\n",
        "print(t2.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n",
            "torch.Size([2, 2])\n"
          ]
        }
      ],
      "execution_count": 22,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dim=0\n",
        "print(torch.cat((t1, t2), dim=dim).shape)\n",
        "print(torch.cat((t1, t2), dim=dim).shape[dim])\n",
        "print(torch.cat((t1, t2), dim=dim)) # to the 0. dim"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 2])\n",
            "4\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6],\n",
            "        [7, 8]])\n"
          ]
        }
      ],
      "execution_count": 23,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dim=1\n",
        "print(torch.cat((t1, t2), dim=1).shape)\n",
        "print(torch.cat((t1, t2), dim=1).shape[dim])\n",
        "print(torch.cat((t1, t2), dim=dim)) # to the 1. dim"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 4])\n",
            "4\n",
            "tensor([[1, 2, 5, 6],\n",
            "        [3, 4, 7, 8]])\n"
          ]
        }
      ],
      "execution_count": 24,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Flattening specific axes of a tensor"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.tensor([\n",
        "    [1,1,1,1],\n",
        "    [1,1,1,1],\n",
        "    [1,1,1,1],\n",
        "    [1,1,1,1]\n",
        "])\n",
        "\n",
        "t2 = torch.tensor([\n",
        "    [2,2,2,2],\n",
        "    [2,2,2,2],\n",
        "    [2,2,2,2],\n",
        "    [2,2,2,2]\n",
        "])\n",
        "\n",
        "t3 = torch.tensor([\n",
        "    [3,3,3,3],\n",
        "    [3,3,3,3],\n",
        "    [3,3,3,3],\n",
        "    [3,3,3,3]\n",
        "])\n",
        "\n",
        "t = torch.stack((t1,t2,t3))\n",
        "t.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "text/plain": [
              "torch.Size([3, 4, 4])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 25,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "each channel indicates it is a image\n",
        "<pre class=\"prettyprint\">&gt; t = t.reshape(3,1,4,4)\n",
        "b=batch\n",
        "c=channel\n",
        "h=height\n",
        "w=width\n",
        "&gt; t\n",
        "tensor(\n",
        "b->[\n",
        "c->[\n",
        "    h->[\n",
        "         w->[1, 1, 1, 1],\n",
        "         w->[1, 1, 1, 1],\n",
        "         w->[1, 1, 1, 1],\n",
        "         w->[1, 1, 1, 1]\n",
        "        ]\n",
        "    ],\n",
        "c->[\n",
        "    h->[\n",
        "         w->[2, 2, 2, 2],\n",
        "         w->[2, 2, 2, 2],\n",
        "         w->[2, 2, 2, 2],\n",
        "         w->[2, 2, 2, 2]\n",
        "        ]\n",
        "    ],\n",
        "c->[\n",
        "    h->[\n",
        "         w->[3, 3, 3, 3],\n",
        "         w->[3, 3, 3, 3],\n",
        "         w->[3, 3, 3, 3],\n",
        "         w->[3, 3, 3, 3]\n",
        "        ]\n",
        "    ]\n",
        "])\n",
        "</pre>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "t = t.reshape(3,1,4,4)\n",
        "t"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": [
              "tensor([[[[1, 1, 1, 1],\n",
              "          [1, 1, 1, 1],\n",
              "          [1, 1, 1, 1],\n",
              "          [1, 1, 1, 1]]],\n",
              "\n",
              "\n",
              "        [[[2, 2, 2, 2],\n",
              "          [2, 2, 2, 2],\n",
              "          [2, 2, 2, 2],\n",
              "          [2, 2, 2, 2]]],\n",
              "\n",
              "\n",
              "        [[[3, 3, 3, 3],\n",
              "          [3, 3, 3, 3],\n",
              "          [3, 3, 3, 3],\n",
              "          [3, 3, 3, 3]]]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 26,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have the <b>first batch</b>\n",
        "<pre class=\"prettyprint\">\n",
        "c->[\n",
        "    h->[\n",
        "         w->[1, 1, 1, 1],\n",
        "         w->[1, 1, 1, 1],\n",
        "         w->[1, 1, 1, 1],\n",
        "         w->[1, 1, 1, 1]\n",
        "        ]\n",
        "    ],\n",
        "...)\n",
        "</pre>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "t[0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 27,
          "data": {
            "text/plain": [
              "tensor([[[1, 1, 1, 1],\n",
              "         [1, 1, 1, 1],\n",
              "         [1, 1, 1, 1],\n",
              "         [1, 1, 1, 1]]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 27,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have the <b>first color</b> channel of the first image\n",
        "<pre class=\"prettyprint\">\n",
        "    h->[\n",
        "         w->[1, 1, 1, 1],\n",
        "         w->[1, 1, 1, 1],\n",
        "         w->[1, 1, 1, 1],\n",
        "         w->[1, 1, 1, 1]\n",
        "        ]\n",
        "...)\n",
        "</pre>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "t[0][0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 28,
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1],\n",
              "        [1, 1, 1, 1],\n",
              "        [1, 1, 1, 1],\n",
              "        [1, 1, 1, 1]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 28,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have the <b>first row</b> of the color channel of the first image\n",
        "<pre class=\"prettyprint\">\n",
        "         w->[1, 1, 1, 1],\n",
        "...)\n",
        "</pre>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "t[0][0][0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 29,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have the <b>first pixel</b> of the first row of the color channel of the first image\n",
        "<pre class=\"prettyprint\">\n",
        "         1\n",
        "...)\n",
        "</pre>"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "t[0][0][0][0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 30,
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 30,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### if you want to flatten the specific dimension you should use Pytorch flatten method\n",
        "start_dim is tell us which axis start to flatten operation<br/>\n",
        "start_dim=1; First access to the color channel"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# the correct flatten\n",
        "print(\"start_dim=1;\")\n",
        "print(t.shape)\n",
        "print(t.flatten(start_dim=1).shape)\n",
        "print(t.flatten(start_dim=1))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start_dim=1;\n",
            "torch.Size([3, 1, 4, 4])\n",
            "torch.Size([3, 16])\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
            "        [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]])\n"
          ]
        }
      ],
      "execution_count": 31,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# just want to show what is going on.\n",
        "print(\"start_dim=0;\")\n",
        "print(t.flatten(start_dim=0).shape)\n",
        "print(t.flatten(start_dim=0))\n",
        "print(\"\\nstart_dim=2;\")\n",
        "print(t.flatten(start_dim=2).shape)\n",
        "print(t.flatten(start_dim=2))\n",
        "print(\"\\nstart_dim=3;\") # nothing happen :)\n",
        "print(t.flatten(start_dim=3).shape)\n",
        "print(t.flatten(start_dim=3))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start_dim=0;\n",
            "torch.Size([48])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
            "\n",
            "start_dim=2;\n",
            "torch.Size([3, 1, 16])\n",
            "tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "\n",
            "        [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]],\n",
            "\n",
            "        [[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]]])\n",
            "\n",
            "start_dim=3;\n",
            "torch.Size([3, 1, 4, 4])\n",
            "tensor([[[[1, 1, 1, 1],\n",
            "          [1, 1, 1, 1],\n",
            "          [1, 1, 1, 1],\n",
            "          [1, 1, 1, 1]]],\n",
            "\n",
            "\n",
            "        [[[2, 2, 2, 2],\n",
            "          [2, 2, 2, 2],\n",
            "          [2, 2, 2, 2],\n",
            "          [2, 2, 2, 2]]],\n",
            "\n",
            "\n",
            "        [[[3, 3, 3, 3],\n",
            "          [3, 3, 3, 3],\n",
            "          [3, 3, 3, 3],\n",
            "          [3, 3, 3, 3]]]])\n"
          ]
        }
      ],
      "execution_count": 32,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Element-wise tensor operations for deep learning"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.tensor([\n",
        "    [1,2],\n",
        "    [3,4]\n",
        "], dtype=torch.float32)\n",
        "\n",
        "t2 = torch.tensor([\n",
        "    [9,8],\n",
        "    [7,6]\n",
        "], dtype=torch.float32)"
      ],
      "outputs": [],
      "execution_count": 33,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1[0][0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 34,
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 34,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t2[0][0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 35,
          "data": {
            "text/plain": [
              "tensor(9.)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 35,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 + t2"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/plain": [
              "tensor([[10., 10.],\n",
              "        [10., 10.]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 36,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(t1 + 2)\n",
        "print(t1 - 2)\n",
        "print(t1 * 2)\n",
        "print(t1 / 2)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[-1.,  0.],\n",
            "        [ 1.,  2.]])\n",
            "tensor([[2., 4.],\n",
            "        [6., 8.]])\n",
            "tensor([[0.5000, 1.0000],\n",
            "        [1.5000, 2.0000]])\n"
          ]
        }
      ],
      "execution_count": 37,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(t1.add(2))\n",
        "print(t1.sub(2))\n",
        "print(t1.mul(2))\n",
        "print(t1.div(2))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[-1.,  0.],\n",
            "        [ 1.,  2.]])\n",
            "tensor([[2., 4.],\n",
            "        [6., 8.]])\n",
            "tensor([[0.5000, 1.0000],\n",
            "        [1.5000, 2.0000]])\n"
          ]
        }
      ],
      "execution_count": 38,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's see broadcasting tensor like numpy"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "np.broadcast_to(2, t1.shape)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 39,
          "data": {
            "text/plain": [
              "array([[2, 2],\n",
              "       [2, 2]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 39,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 + 2"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 40,
          "data": {
            "text/plain": [
              "tensor([[3., 4.],\n",
              "        [5., 6.]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 40,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 + torch.tensor(\n",
        "    np.broadcast_to(2, t1.shape)\n",
        "    ,dtype=torch.float32\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 41,
          "data": {
            "text/plain": [
              "tensor([[3., 4.],\n",
              "        [5., 6.]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 41,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 + 2 == t1 + torch.tensor(\n",
        "                np.broadcast_to(2, t1.shape)\n",
        "                ,dtype=torch.float32\n",
        "                )"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 42,
          "data": {
            "text/plain": [
              "tensor([[True, True],\n",
              "        [True, True]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 42,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.tensor([\n",
        "    [1,1],\n",
        "    [1,1]\n",
        "], dtype=torch.float32)\n",
        "\n",
        "t2 = torch.tensor([2,4], dtype=torch.float32)\n",
        "print(t1.shape)\n",
        "print(t2.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n",
            "torch.Size([2])\n"
          ]
        }
      ],
      "execution_count": 43,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.broadcast_to(t2.numpy(), t1.shape)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 44,
          "data": {
            "text/plain": [
              "array([[2., 4.],\n",
              "       [2., 4.]], dtype=float32)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 44,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 + t2"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 45,
          "data": {
            "text/plain": [
              "tensor([[3., 5.],\n",
              "        [3., 5.]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 45,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I can make a comparison operations to the tensor with scalar values. Thanks to the broadcasting"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([\n",
        "    [0,5,0],\n",
        "    [6,0,7],\n",
        "    [0,8,0]\n",
        "], dtype=torch.float32)"
      ],
      "outputs": [],
      "execution_count": 46,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.eq(0)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 47,
          "data": {
            "text/plain": [
              "tensor([[ True, False,  True],\n",
              "        [False,  True, False],\n",
              "        [ True, False,  True]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 47,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.ge(0)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 48,
          "data": {
            "text/plain": [
              "tensor([[True, True, True],\n",
              "        [True, True, True],\n",
              "        [True, True, True]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 48,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.gt(0)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 49,
          "data": {
            "text/plain": [
              "tensor([[False,  True, False],\n",
              "        [ True, False,  True],\n",
              "        [False,  True, False]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 49,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.lt(0)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 50,
          "data": {
            "text/plain": [
              "tensor([[False, False, False],\n",
              "        [False, False, False],\n",
              "        [False, False, False]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 50,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.le(7)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 51,
          "data": {
            "text/plain": [
              "tensor([[ True,  True,  True],\n",
              "        [ True,  True,  True],\n",
              "        [ True, False,  True]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 51,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t <= torch.tensor([\n",
        "    [7,7,7],\n",
        "    [7,7,7],\n",
        "    [7,7,7]\n",
        "], dtype=torch.float32)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 52,
          "data": {
            "text/plain": [
              "tensor([[ True,  True,  True],\n",
              "        [ True,  True,  True],\n",
              "        [ True, False,  True]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 52,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Element-wise operations using functions"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "t.abs()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 53,
          "data": {
            "text/plain": [
              "tensor([[0., 5., 0.],\n",
              "        [6., 0., 7.],\n",
              "        [0., 8., 0.]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 53,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.sqrt()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 54,
          "data": {
            "text/plain": [
              "tensor([[0.0000, 2.2361, 0.0000],\n",
              "        [2.4495, 0.0000, 2.6458],\n",
              "        [0.0000, 2.8284, 0.0000]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 54,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.neg()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 55,
          "data": {
            "text/plain": [
              "tensor([[-0., -5., -0.],\n",
              "        [-6., -0., -7.],\n",
              "        [-0., -8., -0.]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 55,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.neg().abs()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 56,
          "data": {
            "text/plain": [
              "tensor([[0., 5., 0.],\n",
              "        [6., 0., 7.],\n",
              "        [0., 8., 0.]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 56,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Reduction Ops for Deep Learning\n",
        "A reduction operation on a tensor is an operation that reduces the number of elements contained within the tensor."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([\n",
        "    [0,1,0],\n",
        "    [2,0,2],\n",
        "    [0,3,0]\n",
        "], dtype=torch.float32)"
      ],
      "outputs": [],
      "execution_count": 57,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.sum()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 58,
          "data": {
            "text/plain": [
              "tensor(8.)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 58,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.numel()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 59,
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 59,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.sum().numel() #chain the operations"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 60,
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 60,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.sum().numel() < t.numel() #doesn't protect the number of elements"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 61,
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 61,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.prod()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 62,
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 62,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.mean()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 63,
          "data": {
            "text/plain": [
              "tensor(0.8889)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 63,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.std()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 64,
          "data": {
            "text/plain": [
              "tensor(1.1667)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 64,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reduction operatrions on different dimensations. \n",
        "* Remember we are reducing with respect to axis"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([\n",
        "    [1,1,1,1],\n",
        "    [2,2,2,2],\n",
        "    [3,3,3,3],\n",
        "], dtype=torch.float32)\n",
        "t"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 65,
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [2., 2., 2., 2.],\n",
              "        [3., 3., 3., 3.]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 65,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can think dim. like \n",
        "- dim=0 => there isn't a bracket, you are accessing into all brackets\n",
        "- dim=1 => there is a 1 bracket, you are accessing into all brackets except for 1 bracket"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(t.shape)\n",
        "print(t.shape[0])\n",
        "print(t.shape[1])\n",
        "print(t[0])\n",
        "print(t[1])\n",
        "print(t[2])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 4])\n",
            "3\n",
            "4\n",
            "tensor([1., 1., 1., 1.])\n",
            "tensor([2., 2., 2., 2.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ],
      "execution_count": 66,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(t[0] + t[1] + t[2])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([6., 6., 6., 6.])\n"
          ]
        }
      ],
      "execution_count": 67,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.sum(dim=0)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 68,
          "data": {
            "text/plain": [
              "tensor([6., 6., 6., 6.])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 68,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(t[0].sum())\n",
        "print(t[1].sum())\n",
        "print(t[2].sum())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.)\n",
            "tensor(8.)\n",
            "tensor(12.)\n"
          ]
        }
      ],
      "execution_count": 69,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.sum(dim=1)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 70,
          "data": {
            "text/plain": [
              "tensor([ 4.,  8., 12.])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 70,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "and there is a one thing to you should know. if you are don't use dim. parameter you are accesing to flatten version of tensor"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([\n",
        "    [1,0,0,2],\n",
        "    [0,3,3,0],\n",
        "    [4,0,5,0]\n",
        "], dtype=torch.float32)\n",
        "print(t.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 4])\n"
          ]
        }
      ],
      "execution_count": 85,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.flatten()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 87,
          "data": {
            "text/plain": [
              "tensor([1., 0., 0., 2., 0., 3., 3., 0., 4., 0., 5., 0.])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 87,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.max()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 73,
          "data": {
            "text/plain": [
              "tensor(5.)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 73,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.argmax() # couting from left to right and then top to bottom."
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 74,
          "data": {
            "text/plain": [
              "tensor(10)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 74,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use dim."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "t"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 75,
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 2.],\n",
              "        [0., 3., 3., 0.],\n",
              "        [4., 0., 5., 0.]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 75,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "t.max(dim=0) highlighted\n",
        "tensor([<br/>\n",
        "        0->[[1., 0., 0., <b>2.</b>]],<br/>\n",
        "        1->[[0., <b>3.</b>, 3., 0.]],<br/>\n",
        "        2->[[<b>4.</b>, 0., <b>5.</b>, 0.]]\n",
        "        <br/>])"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "t.max(dim=0) # returns 2 different tensor. First -> values, Second -> indices"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 76,
          "data": {
            "text/plain": [
              "torch.return_types.max(\n",
              "values=tensor([4., 3., 5., 2.]),\n",
              "indices=tensor([2, 1, 2, 0]))"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 76,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.argmax(dim=0) # just returns indices"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 77,
          "data": {
            "text/plain": [
              "tensor([2, 1, 2, 0])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 77,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "t.max(dim=1) highlighted\n",
        "tensor([<br/>\n",
        "        [[1., 0., 0., <b>2.</b>]],<br/>\n",
        "        [[0., <b>3.</b>, 3., 0.]],<br/>\n",
        "        [[4., 0., <b>5.</b>, 0.]]<br/>\n",
        "          0---1---2--3\n",
        "        <br/>])"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "t.max(dim=1)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 78,
          "data": {
            "text/plain": [
              "torch.return_types.max(\n",
              "values=tensor([2., 3., 5.]),\n",
              "indices=tensor([3, 2, 2]))"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 78,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.argmax(dim=1)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 79,
          "data": {
            "text/plain": [
              "tensor([3, 2, 2])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 79,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Accessing elements inside tensors"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.tensor([\n",
        "    [1,2,3],\n",
        "    [4,5,6],\n",
        "    [7,8,9]\n",
        "], dtype=torch.float32)"
      ],
      "outputs": [],
      "execution_count": 80,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.mean()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 81,
          "data": {
            "text/plain": [
              "tensor(5.)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 81,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.mean().item()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 82,
          "data": {
            "text/plain": [
              "5.0"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 82,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.mean(dim=0).tolist() # to the python list"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 83,
          "data": {
            "text/plain": [
              "[4.0, 5.0, 6.0]"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 83,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.mean(dim=0).numpy() # to the numpy array"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 84,
          "data": {
            "text/plain": [
              "array([4., 5., 6.], dtype=float32)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 84,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "0.15.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
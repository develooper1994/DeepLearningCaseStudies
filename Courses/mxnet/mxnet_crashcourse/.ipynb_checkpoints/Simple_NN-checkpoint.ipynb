{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Not needed to specify inputs. Mxnet infers inputs whenever use the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet import nd\n",
    "from mxnet.gluon import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense(None -> 2, linear)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = nn.Dense(2)\n",
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "layer.initialize()  # weight -> {-0.7, 0.7}.uniform, bias -> 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  \n",
      "[[ 0.09762704  0.18568921  0.43037868  0.6885315 ]\n",
      " [ 0.20552671  0.71589124  0.08976638  0.6945034 ]\n",
      " [-0.15269041  0.24712741  0.29178822 -0.23123658]]\n",
      "<NDArray 3x4 @cpu(0)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-0.02524132 -0.00874885]\n",
       " [-0.06026538 -0.01308061]\n",
       " [ 0.02468396 -0.02181557]]\n",
       "<NDArray 3x2 @cpu(0)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = nd.random.uniform(-1, 1, (3,4))\n",
    "print(\"x: \", x)\n",
    "layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-0.00873779 -0.02834515  0.05484822 -0.06206018]\n",
       " [ 0.06491279 -0.03182812 -0.01631819 -0.00312688]]\n",
       "<NDArray 2x4 @cpu(0)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.weight.data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Lenet implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2D(None -> 6, kernel_size=(5, 5), stride=(1, 1), Activation(relu))\n",
       "  (1): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False, global_pool=False, pool_type=max, layout=NCHW)\n",
       "  (2): Conv2D(None -> 16, kernel_size=(3, 3), stride=(1, 1), Activation(relu))\n",
       "  (3): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False, global_pool=False, pool_type=max, layout=NCHW)\n",
       "  (4): Dense(None -> 120, Activation(relu))\n",
       "  (5): Dense(None -> 84, Activation(relu))\n",
       "  (6): Dense(None -> 10, linear)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(\n",
    "    # we can use a tuple to specify a  non-square\n",
    "    nn.Conv2D(channels=6, kernel_size=5, activation=\"relu\"),\n",
    "    nn.MaxPool2D(pool_size=2, strides=2),\n",
    "    nn.Conv2D(channels=16, kernel_size=3, activation=\"relu\"),\n",
    "    nn.MaxPool2D(pool_size=2, strides=2),\n",
    "    # The Dense layer will automatically reshape the 4-D output of last\n",
    "    # maxpooling layer into the 2-D shape: (x.shape[0], x.size/x.shape[0])\n",
    "\n",
    "    # gives output\n",
    "    nn.Dense(120, activation=\"relu\"),\n",
    "    nn.Dense(84, activation=\"relu\"),\n",
    "    nn.Dense(10)\n",
    ")\n",
    "net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.initialize()\n",
    "# Input shape is (batch_size, color_channels, height, width)\n",
    "x = nd.random.uniform(shape=(4,1,28,28))\n",
    "y = net(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6, 1, 5, 5), (84,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(net[0].weight.data().shape, net[5].bias.data().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Flexible NN\n",
    "it is a similar way to creating NN with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MixMLP(\n",
       "  (blk): Sequential(\n",
       "    (0): Dense(None -> 3, Activation(relu))\n",
       "    (1): Dense(None -> 4, Activation(relu))\n",
       "  )\n",
       "  (dense): Dense(None -> 5, linear)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MixMLP(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        # Run `nn.Block`'s init method\n",
    "        super(MixMLP, self).__init__(**kwargs)\n",
    "        self.blk = nn.Sequential()\n",
    "        self.blk.add(nn.Dense(3, activation='relu'),\n",
    "                     nn.Dense(4, activation='relu'))\n",
    "        self.dense = nn.Dense(5)\n",
    "    def forward(self, x):\n",
    "        y = nd.relu(self.blk(x))\n",
    "        print(y)\n",
    "        return self.dense(y)\n",
    "\n",
    "net = MixMLP()\n",
    "net"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
